package readzip;

import java.io.DataOutputStream;
import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class RawByteOutputFormat extends FileOutputFormat<NullWritable, BytesWritable> {

	@Override
	public RecordWriter<NullWritable, BytesWritable> getRecordWriter(TaskAttemptContext taskAttemptContext)
			throws IOException, InterruptedException {
		Configuration conf = taskAttemptContext.getConfiguration();
		String extension = "";
		
		Path file = getDefaultWorkFile(taskAttemptContext, extension);
		FileSystem fs = file.getFileSystem(conf);
		
		FSDataOutputStream fileOutput = fs.create(file, false);
		
		return new ByteRecordWriter(new DataOutputStream(fileOutput));
		
	}
	

}

class ByteRecordWriter extends RecordWriter<NullWritable, BytesWritable> {
	
	private DataOutputStream out;
	
	public ByteRecordWriter(DataOutputStream out) {
		this.out = out;
	}
	
	@Override
	public void close(TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException {
		out.close();
		
	}

	@Override
	public void write(NullWritable key, BytesWritable value) throws IOException, InterruptedException {
		boolean nullValue = value == null;
		if(!nullValue) {
			out.write(value.getBytes(), 0, value.getLength());
		}
		
		
	}
	
}